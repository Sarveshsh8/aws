{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "from dataclasses import dataclass\n",
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "# === Data Class for Configuration ===      # PASS THE CONFIGURATION\n",
    "@dataclass\n",
    "class CampaignInstruction:\n",
    "    natural_language_prompt: str\n",
    "    email_template: str\n",
    "    metadat : str\n",
    "\n",
    "# === Main Data-Aware Email Campaign Class ===\n",
    "class DataDrivenEmailCampaign:\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.csv_path = csv_path\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.schema = self.df.dtypes.to_dict()\n",
    "        self.sample_rows = self.df.head(3).to_dict(orient='records')\n",
    "        self.setup_logging()\n",
    "        self.setup_aws_client()\n",
    "        self.setup_agents()\n",
    "\n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def setup_aws_client(self):\n",
    "        self.bedrock_info = BedrockInfo(\n",
    "            aws_access_key=os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "            aws_secret_key=os.getenv(\"AWS_SECRET_KEY\"),\n",
    "            aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\"),\n",
    "            aws_region=os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
    "        )\n",
    "        self.llm_client = AnthropicBedrockChatCompletionClient(\n",
    "            model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "            model_info=ModelInfo(\n",
    "                vision=False,\n",
    "                function_calling=True,\n",
    "                json_output=True,\n",
    "                family=\"claude\",\n",
    "                structured_output=True\n",
    "            ),\n",
    "            bedrock_info=self.bedrock_info\n",
    "        )\n",
    "        self.llm_config = {\"client\": self.llm_client}\n",
    "\n",
    "    def setup_agents(self):\n",
    "        self.sql_agent = AssistantAgent(\n",
    "            name=\"SQLGenerator\",\n",
    "            system_message=\"\"\"\n",
    "            You are a SQL expert. Based on the provided schema and instruction, generate a SELECT SQL query.\n",
    "            Output JSON: {\"query\": \"SELECT ... WHERE ...;\"}                                                     \n",
    "            \"\"\",\n",
    "            llm_config=self.llm_config,\n",
    "        )\n",
    "\n",
    "        self.email_agent = AssistantAgent(\n",
    "            name=\"EmailCreator\",\n",
    "            system_message=\"\"\"\n",
    "            You are an email copywriting assistant. Based on filtered user data and a prompt, write personalized emails.\n",
    "            Output JSON: List of {\"name\": ..., \"email\": ..., \"subject\": ..., \"body\": ...}\n",
    "            \"\"\",\n",
    "            llm_config=self.llm_config,\n",
    "        )\n",
    "\n",
    "        self.compliance_agent = AssistantAgent(\n",
    "            name=\"ComplianceChecker\",\n",
    "            system_message=\"\"\"\n",
    "            You are a compliance checker. Review email content and validate if it meets GDPR and CAN-SPAM standards.\n",
    "            Output JSON: {\"gdpr\": true/false, \"can_spam\": true/false, \"notes\": \"...\"}\n",
    "            \"\"\",\n",
    "            llm_config=self.llm_config,\n",
    "        )\n",
    "\n",
    "        self.performance_agent = AssistantAgent(\n",
    "            name=\"PerformanceAdvisor\",\n",
    "            system_message=\"\"\"\n",
    "            You are a campaign performance advisor. Based on the campaign objective and user segments, suggest:\n",
    "            - Optimal send time\n",
    "            - A/B testing opportunities\n",
    "            - Subject line improvements\n",
    "            Output JSON: {\"send_time\": ..., \"ab_tests\": [...], \"subject_suggestions\": [...]}\n",
    "            \"\"\",\n",
    "            llm_config=self.llm_config,\n",
    "        )\n",
    "\n",
    "        self.insight_agent = AssistantAgent(\n",
    "            name=\"SegmentInsights\",\n",
    "            system_message=\"\"\"\n",
    "            You are a segmentation analyst. Based on sample user data and schema, identify user segments:\n",
    "            - Dormant, Active, VIP, New\n",
    "            Output JSON: List of {\"user_id\": ..., \"segment\": ..., \"reason\": ...}\n",
    "            \"\"\",\n",
    "            llm_config=self.llm_config,\n",
    "        )\n",
    "\n",
    "        self.user_proxy = UserProxyAgent(\n",
    "            name=\"CampaignManager\",\n",
    "            human_input_mode=\"NEVER\",\n",
    "            code_execution_config={\"work_dir\": \"campaign_data\"},\n",
    "            max_consecutive_auto_reply=3,\n",
    "            is_termination_msg=lambda x: \"EMAIL_CAMPAIGN_DONE\" in x.get(\"content\", \"\")\n",
    "        )\n",
    "\n",
    "        self.group_chat = GroupChat(\n",
    "            agents=[\n",
    "                self.user_proxy,\n",
    "                self.sql_agent,\n",
    "                self.insight_agent,\n",
    "                self.email_agent,\n",
    "                self.compliance_agent,\n",
    "                self.performance_agent\n",
    "            ],\n",
    "            messages=[],\n",
    "            max_round=15\n",
    "        )\n",
    "        self.manager = GroupChatManager(groupchat=self.group_chat, llm_config=self.llm_config)\n",
    "\n",
    "    def execute(self, instruction: CampaignInstruction):\n",
    "        prompt = f\"\"\"\n",
    "        SCHEMA: {json.dumps({k: str(v) for k, v in self.schema.items()})}\n",
    "        SAMPLE ROWS: {json.dumps(self.sample_rows)}\n",
    "\n",
    "        TASK: {instruction.natural_language_prompt}\n",
    "\n",
    "        METADATA : {instruction.metadata}\n",
    "\n",
    "        EMAIL TEMPLATE: {instruction.email_template}\n",
    "\n",
    "        Please generate the SQL query, segment users, and then create compliant, personalized emails.\n",
    "        EMAIL_CAMPAIGN_DONE\n",
    "        \"\"\"\n",
    "        self.user_proxy.initiate_chat(self.manager, message=prompt)\n",
    "        self.save_transcript()\n",
    "\n",
    "    def save_transcript(self):\n",
    "        os.makedirs(\"campaign_data\", exist_ok=True)\n",
    "        ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        with open(f\"campaign_data/transcript_{ts}.json\", \"w\") as f:\n",
    "            json.dump(self.group_chat.messages, f, indent=2)\n",
    "        self.logger.info(\"Saved group chat transcript.\")\n",
    "\n",
    "# === Example Execution ===\n",
    "\n",
    "def run():\n",
    "    campaign = DataDrivenEmailCampaign(\"your_users.csv\")\n",
    "\n",
    "    instruction = CampaignInstruction(\n",
    "        natural_language_prompt=\"Select Premium users inactive for more than 90 days.\",     ## pass the naturel language promt whaterver we want\n",
    "        metadata = f\"{\"pass the column names over here\"}\"\n",
    "        email_template=\"\"\"\n",
    "        Hi {name},\\n\\nWe noticed you haven't logged in for a while. Explore new features in your {account_type} account.\\n\\nLog back in today ‚Üí\\n        \"\"\"\n",
    "    )\n",
    "\n",
    "    campaign.execute(instruction)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "            \"api_type\": \"bedrock\",\n",
    "            \"aws_access_key\": creds.access_key,\n",
    "            \"aws_secret_key\": creds.secret_key,\n",
    "            \"aws_region\": \"us-west-2\",\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL QUERY GENERTION BASED ON THE METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import logging\n",
    "# import boto3\n",
    "# from langchain_aws import BedrockEmbeddings, ChatBedrock\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "# import json\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_community.document_loaders import PyMuPDFLoader, CSVLoader\n",
    "# import altair as alt\n",
    "# import pandas as pd\n",
    "# import vl_convert\n",
    "# from langchain_core.documents import Document\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Use temporary credentials directly\n",
    "# assumed_role_session = boto3.Session(\n",
    "#     aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "#     aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "#     aws_session_token=os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "# )\n",
    "\n",
    "# bedrock_client = assumed_role_session.client(\"bedrock-runtime\")\n",
    "# bedrock_embeddings = BedrockEmbeddings(\n",
    "#     model_id=os.getenv(\"EMBED_MODEL_ID\"),\n",
    "#     client=bedrock_client\n",
    "# )\n",
    "\n",
    "# class TextToSQL:\n",
    "#     def __init__(self, csv_path: str, pdf_path: str, faiss_index_path: str):\n",
    "#         self.csv_path = csv_path\n",
    "#         self.pdf_path = pdf_path\n",
    "#         self.faiss_index_path = faiss_index_path\n",
    "#         self.embeddings = bedrock_embeddings\n",
    "#         self.vectorstore = None\n",
    "#         self.docs = []\n",
    "#         self.load_csv_documents()\n",
    "#         self.load_pdf_documents()\n",
    "#         self.create_vectorstore()\n",
    "#         self.load_vectorstore()\n",
    "#         self.session = boto3.Session(profile_name=\"test\")\n",
    "#         self.client = self.session.client(\"bedrock-runtime\")\n",
    "\n",
    "#     def load_csv_documents(self):\n",
    "#         \"\"\"Loads CSV data and adds metadata.\"\"\"\n",
    "#         if self.csv_path:\n",
    "#             # loader = CSVLoader(file_path=self.csv_path, csv_args={\"delimiter\": \",\", \"quotechar\": '\"'})\n",
    "#             # documents = loader.load()\n",
    "#             df = pd.read_csv(self.csv_path, delimiter=\",\", quotechar='\"')\n",
    "    \n",
    "#             # Create Document objects from DataFrame rows\n",
    "#             documents = []\n",
    "            \n",
    "#             # Option 1: If you want to use a specific column as content\n",
    "#             # Replace 'text_column' with your actual column name containing the text\n",
    "#             for i, row in df.iterrows():\n",
    "#                 content = str(row['text_column'])  # Replace with your column name\n",
    "#                 metadata = {'source': self.csv_path, 'row': i}\n",
    "#                 documents.append(Document(page_content=content, metadata=metadata))\n",
    "            \n",
    "#             text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30)\n",
    "#             split_docs = text_splitter.split_documents(documents)\n",
    "            \n",
    "#             for doc in split_docs:\n",
    "#                 doc.metadata[\"source\"] = \"csv\"\n",
    "            \n",
    "#             self.docs.extend(split_docs)\n",
    "\n",
    "#     def load_pdf_documents(self):\n",
    "#         \"\"\"Loads PDF data and adds metadata (NO OCR REQUIRED).\"\"\"\n",
    "#         if self.pdf_path:\n",
    "#             loader = PyMuPDFLoader(self.pdf_path)  # No OCR required\n",
    "#             documents = loader.load()\n",
    "#             text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30)\n",
    "#             split_docs = text_splitter.split_documents(documents)\n",
    "            \n",
    "#             for doc in split_docs:\n",
    "#                 doc.metadata[\"source\"] = \"pdf\"\n",
    "            \n",
    "#             self.docs.extend(split_docs)\n",
    "\n",
    "#     def create_vectorstores(self):\n",
    "#         \"\"\"Creates and saves the FAISS vector store.\"\"\"\n",
    "#         try:\n",
    "#             sample_text = self.docs[0].page_content\n",
    "#             sample_embedding = self.generate_embedding(sample_text)\n",
    "            \n",
    "#             if sample_embedding is None or len(sample_embedding) == 0:\n",
    "#                 logger.error(\"Embeddings are not generated correctly.\")\n",
    "#                 raise ValueError(\"Embeddings are not generated correctly.\")\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error generating embeddings: {e}\")\n",
    "#             raise\n",
    "\n",
    "#         self.vectorstore = FAISS.from_documents(self.docs, self.embeddings)\n",
    "#         self.vectorstore.save_local(self.faiss_index_path)\n",
    "\n",
    "\n",
    "#     def create_vectorstore(self):\n",
    "#         \"\"\"Loads an existing FAISS index if available; otherwise, creates and saves a new one.\"\"\"\n",
    "#         try:\n",
    "#             # Check if FAISS index exists\n",
    "#             if os.path.exists(self.faiss_index_path):\n",
    "#                 logger.info(f\"FAISS index found at {self.faiss_index_path}, loading it...\")\n",
    "#                 self.vectorstore = FAISS.load_local(\n",
    "#                     self.faiss_index_path, self.embeddings, allow_dangerous_deserialization=True\n",
    "#                 )\n",
    "#                 logger.info(\"FAISS index loaded successfully.\")\n",
    "#                 return  # Correctly returning after loading\n",
    "\n",
    "#             if not self.docs:\n",
    "#                 logger.error(\"Document list is empty. Cannot create vector store.\")\n",
    "#                 raise ValueError(\"Document list is empty.\")\n",
    "\n",
    "#             sample_text = self.docs[0].page_content\n",
    "#             sample_embedding = self.generate_embedding(sample_text)\n",
    "\n",
    "#             if not sample_embedding or len(sample_embedding) == 0:\n",
    "#                 logger.error(\"Embeddings are not generated correctly.\")\n",
    "#                 raise ValueError(\"Embeddings are not generated correctly.\")\n",
    "\n",
    "#             if not hasattr(self, 'embeddings') or self.embeddings is None:\n",
    "#                 logger.error(\"Embeddings function is not defined.\")\n",
    "#                 raise ValueError(\"Embeddings function is not defined.\")\n",
    "\n",
    "#             # Create and save FAISS vector store\n",
    "#             logger.info(\"No existing FAISS index found. Creating a new one...\")\n",
    "#             self.vectorstore = FAISS.from_documents(self.docs, self.embeddings)\n",
    "#             self.vectorstore.save_local(self.faiss_index_path)\n",
    "#             logger.info(f\"FAISS vector store successfully saved at {self.faiss_index_path}\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error while handling FAISS index: {e}\")\n",
    "#             raise\n",
    "\n",
    "\n",
    "#     def generate_embedding(self, text):\n",
    "#         \"\"\"Generates embeddings for the given text.\"\"\"\n",
    "#         return self.embeddings.embed_query(text)\n",
    "\n",
    "#     def load_vectorstore(self):\n",
    "#         \"\"\"Loads the FAISS vector store from disk.\"\"\"\n",
    "#         self.vectorstore = FAISS.load_local(self.faiss_index_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "#     def retrieve_context(self, query: str, k: int = 10):\n",
    "#         \"\"\"Retrieves relevant context from both CSV (for SQL) and PDF (for explanations).\"\"\"\n",
    "        \n",
    "#         retrieved_docs = self.vectorstore.similarity_search(query, k=k)\n",
    "        \n",
    "#         csv_content = \"\\n\".join([doc.page_content for doc in retrieved_docs if doc.metadata.get(\"source\") == \"csv\"])\n",
    "#         pdf_content = \"\\n\".join([doc.page_content for doc in retrieved_docs if doc.metadata.get(\"source\") == \"pdf\"])\n",
    "\n",
    "#         return pdf_content, csv_content\n",
    "    \n",
    "    \n",
    "\n",
    "#     def save_pie_chart(self,data, filename=\"dynamic_pie_chart.png\", inner_radius=50):\n",
    "#         \"\"\"\n",
    "#         Generates a pie chart and saves it as PNG.\n",
    "\n",
    "#         Parameters:\n",
    "#             data (list of dict): Data format [{\"category\": value, \"count\": value}]\n",
    "#             filename (str): Output PNG file name.\n",
    "#             inner_radius (int): Set to 0 for full pie, default 50 for donut chart.\n",
    "#         \"\"\"\n",
    "#         df = pd.DataFrame(data[\"Visualization\"][\"data\"][\"values\"])  # Directly use data\n",
    "\n",
    "#         chart = alt.Chart(df).mark_arc(innerRadius=inner_radius).encode(\n",
    "#             theta=alt.Theta(\"count:Q\"),\n",
    "#             color=alt.Color(df.columns[0] + \":N\")  # Auto-detect category\n",
    "#         )\n",
    "\n",
    "#         png_bytes = vl_convert.vegalite_to_png(chart.to_json())\n",
    "#         with open(filename, \"wb\") as f:\n",
    "#             f.write(png_bytes)\n",
    "\n",
    "#         print(f\"Pie chart saved as '{filename}'\")\n",
    "    \n",
    "#     def generate_sql_query(self, query: str):\n",
    "#         \"\"\"Generates an SQL query based on the retrieved context and user query.\"\"\"\n",
    "#         pdf_context, csv_context = self.retrieve_context(query)\n",
    "#         json_output ={\n",
    "#             \"Answer\": \"To analyze the gender distribution across the data, we can generate a count of students by gender and visualize it in a bar chart.\",\n",
    "#             \"SQL Query\": \"SELECT gender, COUNT(*) as count FROM students GROUP BY gender\",\n",
    "#             \"SQL Query Answer\": \"male, 8\\nfemale, 4\",\n",
    "#             \"Visualization\": {\n",
    "#                 \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "#                 \"description\": \"Gender Distribution\",\n",
    "#                 \"data\": {\n",
    "#                 \"values\": [\n",
    "#                     {\"gender\": \"male\", \"count\": 8},\n",
    "#                     {\"gender\": \"female\", \"count\": 4}\n",
    "#                 ]\n",
    "#                 },\n",
    "#                 \"mark\": \"bar\",\n",
    "#                 \"encoding\": {\n",
    "#                 \"x\": {\"field\": \"gender\", \"type\": \"nominal\"},\n",
    "#                 \"y\": {\"field\": \"count\", \"type\": \"quantitative\"},\n",
    "#                 \"color\": {\"field\": \"gender\", \"type\": \"nominal\"}\n",
    "#         }\n",
    "#         }\n",
    "#         }       # Convert json_output to a JSON string\n",
    "#         json_output_str = json.dumps(json_output, indent=2)\n",
    "#         json_output_str = json_output_str.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "#         # Create the prompt for Claude 3.5 Sonnet\n",
    "#         prompt = {\n",
    "#             \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "#             \"max_tokens\": 2048,\n",
    "#             \"system\": \"\"\"You are an expert AI assistant for Text-to-SQL conversion.\n",
    "\n",
    "#             **Task:**\n",
    "#             - Analyze the provided PDF for context and the CSV data structure to understand the schema and answer the user's question:\n",
    "#             1. If it requires data retrieval, generate a SQL query and summarize the answer using the PDF context.\n",
    "#             2. If it doesn't require SQL querying, provide only an explanation and set the SQL query to null.\n",
    "#             3. If the question involves time-based data or any data that would benefit from visualization (especially date ranges, timestamps, or categorical distributions), also generate a Vega-Lite specification.\"\"\",\n",
    "            \n",
    "            \n",
    "#             \"messages\": [\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": f\"\"\"Explanation:\\n{pdf_context}\\n\\nData Structure:\\n{csv_context}\\n\\nQuestion: {query}\\n\\n**Instructions:**\n",
    "\n",
    "#             Format your response ONLY as a valid JSON object with these fields:\n",
    "#             - Answer: Your explanation based on the PDF context\n",
    "#             - SQL Query: The SQL query to retrieve the requested data, or null if no query is needed\n",
    "#             - SQL Query Answer: The result of the SQL query in a simple format\n",
    "#             - Visualization: When appropriate, include a Vega-Lite JSON specification for visualization\n",
    "\n",
    "#             For Vega-Lite visualizations:\n",
    "#             - Use appropriate chart types based on the data (bar charts for categorical data, line charts for time series, etc.)\n",
    "#             - Keep the specification clean and minimal\n",
    "#             - For categorical distributions, use bar charts or pie charts as appropriate\n",
    "#             - IMPORTANT: Do not add any text before or after the JSON object. Your entire response should be only the JSON object itself.\n",
    "\n",
    "#             Example of exactly how your response should look:\n",
    "#             {json_output_str}\"\"\"\n",
    "            \n",
    "#                 }\n",
    "#             ],\n",
    "#             \"temperature\": 0.0\n",
    "#         }\n",
    "\n",
    "#         # Convert prompt to JSON string\n",
    "#         input_text = json.dumps(prompt)\n",
    "        \n",
    "#         # Call Claude 3.5 Sonnet model\n",
    "#         response = self.client.invoke_model(\n",
    "#             modelId=os.getenv(\"MODEL_ID\"), \n",
    "#             body=input_text\n",
    "#         )\n",
    "\n",
    "#         # Parse the response\n",
    "#         response_body = json.loads(response['body'].read().decode(\"utf-8\"))\n",
    "#         sql_query = response_body['content'][0]['text']\n",
    "#         out = json.loads(sql_query)\n",
    "#         try:\n",
    "#             self.save_pie_chart(out)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "       \n",
    "#         return sql_query\n",
    "    \n",
    "#     def generate_sql_query_with_stream(self, query: str):\n",
    "#         \"\"\"Generates an SQL query based on the retrieved context and user query with streaming.\"\"\"\n",
    "#         pdf_context, csv_context = self.retrieve_context(query)\n",
    "#         json_output = {\n",
    "#             \"Answer\": \"To analyze the gender distribution across the data, we can generate a count of students by gender and visualize it in a bar chart.\",\n",
    "#             \"SQL Query\": \"SELECT gender, COUNT(*) as count FROM students GROUP BY gender\",\n",
    "#             \"SQL Query Answer\": \"male, 8\\nfemale, 4\",\n",
    "#             \"Visualization\": {\n",
    "#                 \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n",
    "#                 \"description\": \"Gender Distribution\",\n",
    "#                 \"data\": {\n",
    "#                 \"values\": [\n",
    "#                     {\"gender\": \"male\", \"count\": 8},\n",
    "#                     {\"gender\": \"female\", \"count\": 4}\n",
    "#                 ]\n",
    "#                 },\n",
    "#                 \"mark\": \"bar\",\n",
    "#                 \"encoding\": {\n",
    "#                 \"x\": {\"field\": \"gender\", \"type\": \"nominal\"},\n",
    "#                 \"y\": {\"field\": \"count\", \"type\": \"quantitative\"},\n",
    "#                 \"color\": {\"field\": \"gender\", \"type\": \"nominal\"}\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "        \n",
    "#         # Convert json_output to a JSON string\n",
    "#         json_output_str = json.dumps(json_output, indent=2)\n",
    "#         json_output_str = json_output_str.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "#         # Create the prompt for Claude 3.5 Sonnet\n",
    "#         prompt = {\n",
    "#             \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "#             \"max_tokens\": 2048,\n",
    "#             \"system\": \"\"\"You are an expert AI assistant for Text-to-SQL conversion.\n",
    "\n",
    "#             **Task:**\n",
    "#             - Analyze the provided PDF for context and the CSV data structure to understand the schema and answer the user's question:\n",
    "#             1. If it requires data retrieval, generate a SQL query and summarize the answer using the PDF context.\n",
    "#             2. If it doesn't require SQL querying, provide only an explanation and set the SQL query to null.\n",
    "#             3. If the question involves time-based data or any data that would benefit from visualization (especially date ranges, timestamps, or categorical distributions), also generate a Vega-Lite specification.\"\"\",\n",
    "            \n",
    "#             \"messages\": [\n",
    "#                 {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": f\"\"\"Explanation:\\n{pdf_context}\\n\\nData Structure:\\n{csv_context}\\n\\nQuestion: {query}\\n\\n**Instructions:**\n",
    "\n",
    "#             Format your response ONLY as a valid JSON object with these fields:\n",
    "#             - Answer: Your explanation based on the PDF context\n",
    "#             - SQL Query: The SQL query to retrieve the requested data, or null if no query is needed\n",
    "#             - SQL Query Answer: The result of the SQL query in a simple format\n",
    "#             - Visualization: When appropriate, include a Vega-Lite JSON specification for visualization\n",
    "\n",
    "#             For Vega-Lite visualizations:\n",
    "#             - Use appropriate chart types based on the data (bar charts for categorical data, line charts for time series, etc.)\n",
    "#             - Keep the specification clean and minimal\n",
    "#             - For categorical distributions, use bar charts or pie charts as appropriate\n",
    "#             - IMPORTANT: Do not add any text before or after the JSON object. Your entire response should be only the JSON object itself.\n",
    "\n",
    "#             Example of exactly how your response should look:\n",
    "#             {json_output_str}\"\"\"\n",
    "#                 }\n",
    "#             ],\n",
    "#             \"temperature\": 0.0\n",
    "#         }\n",
    "\n",
    "#         # Convert prompt to JSON string\n",
    "#         input_text = json.dumps(prompt)\n",
    "        \n",
    "#         # Call Claude 3.5 Sonnet model with streaming\n",
    "#         response_stream = self.client.invoke_model_with_response_stream(\n",
    "#             modelId=os.getenv(\"MODEL_ID\"),\n",
    "#             body=input_text\n",
    "#         )\n",
    "        \n",
    "#         # Process the streaming response\n",
    "#         complete_response = \"\"\n",
    "        \n",
    "#         for event in response_stream[\"body\"]:\n",
    "#             if \"chunk\" in event:\n",
    "#                 chunk_data = json.loads(event[\"chunk\"][\"bytes\"].decode(\"utf-8\"))\n",
    "#                 if \"content\" in chunk_data and len(chunk_data[\"content\"]) > 0:\n",
    "#                     text_chunk = chunk_data[\"content\"][0].get(\"text\", \"\")\n",
    "#                     complete_response += text_chunk\n",
    "#                     # We yield each chunk as it arrives\n",
    "#                     yield text_chunk, complete_response\n",
    "        \n",
    "#         # Try to parse the final response and save pie chart\n",
    "#         try:\n",
    "#             final_out = json.loads(complete_response)\n",
    "#             try:\n",
    "#                 self.save_pie_chart(final_out)\n",
    "#             except:\n",
    "#                 pass\n",
    "#         except json.JSONDecodeError:\n",
    "#             pass\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     text2sql = TextToSQL(csv_path=\"data/data.csv\", pdf_path=\"data/data.pdf\", faiss_index_path=\"faiss_index\")\n",
    "#     query = \"Fetch the GPA of id number 1141\"\n",
    "#     # query = \"What is ID and Class\"\n",
    "#     sql_query = text2sql.generate_sql_query(query)\n",
    "#     print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/sarveshharikant/EXIMIETAS/git_AWS/aws/misc/dataset/data.csv\")\n",
    "column_names = df.columns.astype(str).tolist()\n",
    "\n",
    "print(\"list of column names\",column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE SAME WAY YOU CAN CHANGE THE PROMPT IN YOUR INVOKING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "system_prompt = '''\n",
    "You are a specialized SQL query generation agent. Your task is to create simple SQL queries based on user requests and provided column names.\n",
    "\n",
    "Output format must be strictly in JSON:\n",
    "{\"SQL\": \"SELECT ID, gender\\nFROM table_name\"}\n",
    "\n",
    "Generate only the JSON output without any additional information or explanations.\n",
    "'''\n",
    "\n",
    "user_prompt = f\"{column_names} fetch me the id and gender\"    ## PASS THE COLUMNS NAME IN THSI column_names\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": user_prompt\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "response = bedrock_runtime.converse(\n",
    "    system = [\n",
    "        {\n",
    "          \"text\": system_prompt\n",
    "        }\n",
    "    ],\n",
    "    modelId = MODEL_ID,\n",
    "    messages = messages\n",
    ")\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = json.loads(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['SQL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ans = {\"columns\": ['banker', 'oppuruting'], 'data': [['jame',1], ['andrew', 2],['jame',1], ['andrew', 2]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ans['data'], columns=ans['columns'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from aws_rag_pdf import TextToSQL\n",
    "import json\n",
    "import time  # For simulating streaming delay\n",
    "\n",
    "# Global variables to store uploaded file paths\n",
    "csv_path = None\n",
    "pdf_path = None\n",
    "text2sql = None  \n",
    "\n",
    "@cl.on_message\n",
    "async def handle_message(message: cl.Message):\n",
    "    global csv_path, pdf_path, text2sql\n",
    "\n",
    "    # Check if files are uploaded\n",
    "    if message.elements:\n",
    "        for uploaded_file in message.elements:\n",
    "            file_path = uploaded_file.path  \n",
    "            \n",
    "            if file_path.endswith(\".csv\"):\n",
    "                csv_path = file_path\n",
    "            elif file_path.endswith(\".pdf\"):\n",
    "                pdf_path = file_path\n",
    "\n",
    "        if csv_path and pdf_path:\n",
    "            text2sql = TextToSQL(csv_path, pdf_path, \"faiss_index\")\n",
    "            await cl.Message(content=\"‚úÖ CSV and PDF uploaded successfully! Now ask your question.\").send()\n",
    "        elif csv_path:\n",
    "            await cl.Message(content=\"‚úÖ CSV uploaded! Now upload a PDF.\").send()\n",
    "        elif pdf_path:\n",
    "            await cl.Message(content=\"‚úÖ PDF uploaded! Now upload a CSV.\").send()\n",
    "        return\n",
    "\n",
    "    # Ensure both CSV and PDF are uploaded before processing queries\n",
    "    if not csv_path or not pdf_path:\n",
    "        await cl.Message(content=\"‚ö†Ô∏è Please upload both a CSV and a PDF first.\").send()\n",
    "        return\n",
    "\n",
    "    # Process user query after both files are uploaded\n",
    "    user_query = message.content.strip()\n",
    "    \n",
    "    # Create a placeholder for streaming response\n",
    "    msg = cl.Message(content=\"Generating SQL Query...\\n\")\n",
    "    await msg.send()\n",
    "    \n",
    "    response = text2sql.generate_sql_query(user_query)\n",
    "    out = json.loads(response)\n",
    "\n",
    "    # Extract answer and SQL details\n",
    "    Answer = out.get('Answer', 'No answer provided')\n",
    "    SQL = out.get('SQL Query', None)\n",
    "    ans = out.get('SQL Query Answer', None)\n",
    "\n",
    "    # Stream the SQL answer word by word\n",
    "    result = f\"**Answer:** \"\n",
    "    for word in Answer.split():\n",
    "        result += word + \" \"\n",
    "        msg.content = result\n",
    "        await msg.update()\n",
    "        time.sleep(0.1)  # Simulating streaming effect\n",
    "\n",
    "    # Stream the SQL query word by word\n",
    "    if SQL:\n",
    "        result += f\"\\n\\n```sql\\n\"\n",
    "        for word in SQL.split():\n",
    "            result += word + \" \"\n",
    "            msg.content = result\n",
    "            await msg.update()\n",
    "            time.sleep(0.1)\n",
    "        result += \"\\n```\"\n",
    "\n",
    "    # Final update with SQL query output\n",
    "    msg.content += f\"\\n\\n**Output:** {ans}\"\n",
    "    await msg.update()\n",
    "\n",
    "    # ‚úÖ **Display the already saved Pie Chart Image**\n",
    "    file_path = \"dynamic_pie_chart.png\"\n",
    "    if os.path.exists(file_path):\n",
    "        await cl.Message(\n",
    "            content=\"üìä **Generated Pie Chart:**\",\n",
    "            elements=[cl.Image(path=file_path)]\n",
    "        ).send()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cl.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.credentials import create_assume_role_refresher as carr\n",
    "from botocore.credentials import DeferredRefreshableCredentials as DRC\n",
    "from boto3.session import Session\n",
    "import os\n",
    "\n",
    "def get_credentials():\n",
    "    session = Session(region_name=\"us-east-1\")\n",
    "\n",
    "\n",
    "    session._session._credentials = DRC(\n",
    "        refresh_using=carr(session.client(\"sts\"),\n",
    "        {\n",
    "            \"RoleArn\": \"arn:aws:iam::942286715197:role/app-bedrock-access-900858-us-east-1\",\n",
    "            \"RoleSessionName\": \"test\"\n",
    "        }),\n",
    "        method=\"sts-assume-role\"\n",
    "    )\n",
    "\n",
    "    credentials  = session.get_credentials().get_frozen_credentials()\n",
    "    access_key = credentials.access_key\n",
    "    secret_key = credentials.secret_key\n",
    "    token = credentials.token\n",
    "    \n",
    "\n",
    "    # Your AWS credentials\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = access_key\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = secret_key\n",
    "    os.environ[\"AWS_SESSION_TOKEN\"] = token\n",
    "    os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
    "\n",
    "    return access_key, secret_key, token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class to check the credentials update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from botocore.credentials import create_assume_role_refresher as carr\n",
    "from botocore.credentials import DeferredRefreshableCredentials as DRC\n",
    "from boto3.session import Session\n",
    "\n",
    "class AWSCredentialsManager:\n",
    "    def __init__(self, role_arn, region=\"us-east-1\"):\n",
    "        self.role_arn = role_arn\n",
    "        self.region = region\n",
    "        self.session = Session(region_name=self.region)\n",
    "        self.access_key = None\n",
    "        self.secret_key = None\n",
    "        self.token = None\n",
    "\n",
    "    def assume_role(self):\n",
    "        \"\"\"Assumes the AWS role and sets credentials.\"\"\"\n",
    "        self.session._session._credentials = DRC(\n",
    "            refresh_using=carr(\n",
    "                self.session.client(\"sts\"),  \n",
    "                {\n",
    "                    \"RoleArn\": self.role_arn,\n",
    "                    \"RoleSessionName\": \"test\"\n",
    "                }\n",
    "            ),\n",
    "            method=\"sts-assume-role\"\n",
    "        )\n",
    "\n",
    "        credentials = self.session.get_credentials().get_frozen_credentials()\n",
    "        self.access_key = credentials.access_key\n",
    "        self.secret_key = credentials.secret_key\n",
    "        self.token = credentials.token\n",
    "\n",
    "        # Explicitly set the environment variables\n",
    "        os.environ[\"AWS_ACCESS_KEY_ID\"] = self.access_key\n",
    "        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = self.secret_key\n",
    "        os.environ[\"AWS_SESSION_TOKEN\"] = self.token\n",
    "        os.environ[\"AWS_REGION\"] = self.region\n",
    "\n",
    "        # Verify they are set\n",
    "        print(\"AWS_ACCESS_KEY_ID:\", os.environ.get(\"AWS_ACCESS_KEY_ID\"))\n",
    "        print(\"AWS_SECRET_ACCESS_KEY:\", os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "        print(\"AWS_SESSION_TOKEN:\", os.environ.get(\"AWS_SESSION_TOKEN\"))\n",
    "        print(\"AWS_REGION:\", os.environ.get(\"AWS_REGION\"))\n",
    "\n",
    "        return self.access_key, self.secret_key, self.token\n",
    "\n",
    "# Usage\n",
    "aws_manager = AWSCredentialsManager(role_arn=\"arn:aws:iam::942286715197:role/app-bedrock-access-900858-us-east-1\")\n",
    "aws_manager.assume_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from botocore.credentials import create_assume_role_refresher as carr\n",
    "from botocore.credentials import DeferredRefreshableCredentials as DRC\n",
    "from boto3.session import Session\n",
    "\n",
    "class AWSCredentialsManager:\n",
    "    def __init__(self, role_arn, region=\"us-east-1\"):\n",
    "        self.role_arn = role_arn\n",
    "        self.region = region\n",
    "        self.session = Session(region_name=self.region)\n",
    "        self.access_key = None\n",
    "        self.secret_key = None\n",
    "        self.token = None\n",
    "\n",
    "    def assume_role(self):\n",
    "        \"\"\"Assumes the AWS role and sets credentials globally.\"\"\"\n",
    "        self.session._session._credentials = DRC(\n",
    "            refresh_using=carr(\n",
    "                self.session.client(\"sts\"),  \n",
    "                {\n",
    "                    \"RoleArn\": self.role_arn,\n",
    "                    \"RoleSessionName\": \"test\"\n",
    "                }\n",
    "            ),\n",
    "            method=\"sts-assume-role\"\n",
    "        )\n",
    "\n",
    "        credentials = self.session.get_credentials().get_frozen_credentials()\n",
    "        self.access_key = credentials.access_key\n",
    "        self.secret_key = credentials.secret_key\n",
    "        self.token = credentials.token\n",
    "\n",
    "        \n",
    "        os.system(f'setx AWS_ACCESS_KEY_ID \"{self.access_key}\"')\n",
    "        os.system(f'setx AWS_SECRET_ACCESS_KEY \"{self.secret_key}\"')\n",
    "        os.system(f'setx AWS_SESSION_TOKEN \"{self.token}\"')\n",
    "        os.system(f'setx AWS_REGION \"{self.region}\"')\n",
    "        \n",
    "\n",
    "        # Verify they are set\n",
    "        print(\"AWS_ACCESS_KEY_ID:\", os.environ.get(\"AWS_ACCESS_KEY_ID\"))\n",
    "        print(\"AWS_SECRET_ACCESS_KEY:\", os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "        print(\"AWS_SESSION_TOKEN:\", os.environ.get(\"AWS_SESSION_TOKEN\"))\n",
    "        print(\"AWS_REGION:\", os.environ.get(\"AWS_REGION\"))\n",
    "\n",
    "        return self.access_key, self.secret_key, self.token\n",
    "\n",
    "# Usage\n",
    "aws_manager = AWSCredentialsManager(role_arn=\"arn:aws:iam::942286715197:role/app-bedrock-access-900858-us-east-1\")\n",
    "aws_manager.assume_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from botocore.credentials import create_assume_role_refresher as carr\n",
    "from botocore.credentials import DeferredRefreshableCredentials as DRC\n",
    "from boto3.session import Session\n",
    "\n",
    "class AWSCredentialsManager:\n",
    "    def __init__(self, role_arn, region=\"us-east-1\"):\n",
    "        self.role_arn = role_arn\n",
    "        self.region = region\n",
    "        self.session = Session(region_name=self.region)\n",
    "        self.access_key = None\n",
    "        self.secret_key = None\n",
    "        self.token = None\n",
    "\n",
    "    def assume_role(self):\n",
    "        \"\"\"Assumes the AWS role and sets credentials.\"\"\"\n",
    "        self.session._session._credentials = DRC(\n",
    "            refresh_using=carr(\n",
    "                self.session.client(\"sts\"),  \n",
    "                {\n",
    "                    \"RoleArn\": self.role_arn,\n",
    "                    \"RoleSessionName\": \"test\"\n",
    "                }\n",
    "            ),\n",
    "            method=\"sts-assume-role\"\n",
    "        )\n",
    "\n",
    "        credentials = self.session.get_credentials().get_frozen_credentials()\n",
    "        self.access_key = credentials.access_key\n",
    "        self.secret_key = credentials.secret_key\n",
    "        self.token = credentials.token\n",
    "\n",
    "        # Explicitly set the environment variables for the current session\n",
    "        os.environ[\"AWS_ACCESS_KEY_ID\"] = self.access_key\n",
    "        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = self.secret_key\n",
    "        os.environ[\"AWS_SESSION_TOKEN\"] = self.token\n",
    "        os.environ[\"AWS_REGION\"] = self.region\n",
    "\n",
    "        # Use os.system to set them in the shell as well (for immediate use in the terminal)\n",
    "        os.system(f'set AWS_ACCESS_KEY_ID={self.access_key}')\n",
    "        os.system(f'set AWS_SECRET_ACCESS_KEY={self.secret_key}')\n",
    "        os.system(f'set AWS_SESSION_TOKEN={self.token}')\n",
    "        os.system(f'set AWS_REGION={self.region}')\n",
    "\n",
    "        # Verify they are set\n",
    "        print(\"AWS_ACCESS_KEY_ID:\", os.environ.get(\"AWS_ACCESS_KEY_ID\"))\n",
    "        print(\"AWS_SECRET_ACCESS_KEY:\", os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "        print(\"AWS_SESSION_TOKEN:\", os.environ.get(\"AWS_SESSION_TOKEN\"))\n",
    "        print(\"AWS_REGION:\", os.environ.get(\"AWS_REGION\"))\n",
    "\n",
    "        return self.access_key, self.secret_key, self.token\n",
    "\n",
    "# Usage\n",
    "aws_manager = AWSCredentialsManager(role_arn=\"arn:aws:iam::942286715197:role/app-bedrock-access-900858-us-east-1\")\n",
    "aws_manager.assume_role()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOREFRESH CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "from botocore.credentials import create_assume_role_refresher as carr\n",
    "from botocore.credentials import DeferredRefreshableCredentials as DRC\n",
    "from boto3.session import Session\n",
    "\n",
    "# AWS profiles to update\n",
    "PROFILES = [\"adfd\", \"test\"]\n",
    "\n",
    "# Role ARN (Modify if needed)\n",
    "ROLE_ARN = \"arn:aws:iam::942286715197:role/app-bedrock-access-900858-us-east-1\"\n",
    "\n",
    "def get_credentials():\n",
    "    \"\"\"Fetches temporary AWS credentials using STS assume role.\"\"\"\n",
    "    session = Session(region_name=\"us-east-1\")\n",
    "    session._session._credentials = DRC(\n",
    "        refresh_using=carr(session.client(\"sts\"), {\"RoleArn\": ROLE_ARN, \"RoleSessionName\": \"test\"}),\n",
    "        method=\"sts-assume-role\"\n",
    "    )\n",
    "\n",
    "    credentials = session.get_credentials().get_frozen_credentials()\n",
    "    return credentials.access_key, credentials.secret_key, credentials.token\n",
    "\n",
    "def update_aws_credentials_file(access_key, secret_key, token):\n",
    "    \"\"\"Updates ~/.aws/credentials file with new tokens for both profiles.\"\"\"\n",
    "    aws_credentials_path = os.path.expanduser(\"~/.aws/credentials\")\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(aws_credentials_path)\n",
    "\n",
    "    for profile in PROFILES:\n",
    "        if profile not in config:\n",
    "            config[profile] = {}\n",
    "\n",
    "        config[profile][\"aws_access_key_id\"] = access_key\n",
    "        config[profile][\"aws_secret_access_key\"] = secret_key\n",
    "        config[profile][\"aws_session_token\"] = token\n",
    "        config[profile][\"region\"] = \"us-east-1\"\n",
    "\n",
    "    with open(aws_credentials_path, \"w\") as configfile:\n",
    "        config.write(configfile)\n",
    "\n",
    "    print(f\"‚úÖ AWS credentials file updated for profiles: {', '.join(PROFILES)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fetches credentials and updates AWS credentials file once (manual execution).\"\"\"\n",
    "    access_key, secret_key, token = get_credentials()\n",
    "    update_aws_credentials_file(access_key, secret_key, token)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "from dotenv import load_dotenv, set_key\n",
    "from botocore.credentials import create_assume_role_refresher as carr\n",
    "from botocore.credentials import DeferredRefreshableCredentials as DRC\n",
    "from boto3.session import Session\n",
    "\n",
    "# Load existing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# AWS profiles\n",
    "PROFILES = [\"adfs\", \"test\"]\n",
    "\n",
    "# Role ARN for `test` profile\n",
    "ROLE_ARN = \"arn:aws:iam::942286715197:role/app-bedrock-access-900858-us-east-1\"\n",
    "\n",
    "# Paths\n",
    "AWS_CREDENTIALS_PATH = os.path.expanduser(\"~/.aws/credentials\")\n",
    "ENV_FILE_PATH = os.path.join(os.getcwd(), \".env\")  # Assumes .env is in the current directory\n",
    "\n",
    "def get_credentials():\n",
    "    \"\"\"Fetches temporary AWS credentials using STS assume role.\"\"\"\n",
    "    session = Session(region_name=\"us-east-1\")\n",
    "    session._session._credentials = DRC(\n",
    "        refresh_using=carr(session.client(\"sts\"), {\"RoleArn\": ROLE_ARN, \"RoleSessionName\": \"test\"}),\n",
    "        method=\"sts-assume-role\"\n",
    "    )\n",
    "\n",
    "    credentials = session.get_credentials().get_frozen_credentials()\n",
    "    return credentials.access_key, credentials.secret_key, credentials.token, ROLE_ARN\n",
    "\n",
    "def update_aws_credentials_file(access_key, secret_key, token, assumed_role):\n",
    "    \"\"\"Updates ~/.aws/credentials file with new tokens for test and syncs adfd's role ARN with '/test' suffix.\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(AWS_CREDENTIALS_PATH)\n",
    "\n",
    "    for profile in PROFILES:\n",
    "        if profile not in config:\n",
    "            config[profile] = {}\n",
    "\n",
    "        config[profile][\"aws_access_key_id\"] = access_key\n",
    "        config[profile][\"aws_secret_access_key\"] = secret_key\n",
    "        config[profile][\"aws_session_token\"] = token\n",
    "        config[profile][\"region\"] = \"us-east-1\"\n",
    "\n",
    "    # Sync adfd's assumed role with test and append \"/test\"\n",
    "    config[\"adfs\"][\"aws_assumed_role_arn\"] = assumed_role + \"/test\"\n",
    "\n",
    "    with open(AWS_CREDENTIALS_PATH, \"w\") as configfile:\n",
    "        config.write(configfile)\n",
    "\n",
    "    print(f\"‚úÖ AWS credentials file updated for profiles: {', '.join(PROFILES)}\")\n",
    "    print(f\"üîÑ Synced 'adfs' assumed role with 'test': {assumed_role}/test\")\n",
    "\n",
    "def update_env_file(access_key, secret_key, token):\n",
    "    \"\"\"Updates .env file with new AWS credentials.\"\"\"\n",
    "    if os.path.exists(ENV_FILE_PATH):\n",
    "        set_key(ENV_FILE_PATH, \"AWS_ACCESS_KEY_ID\", access_key)\n",
    "        set_key(ENV_FILE_PATH, \"AWS_SECRET_ACCESS_KEY\", secret_key)\n",
    "        set_key(ENV_FILE_PATH, \"AWS_SESSION_TOKEN\", token)\n",
    "        print(\"‚úÖ .env file updated!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No .env file found! Skipping update.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fetches credentials and updates AWS credentials + .env file.\"\"\"\n",
    "    access_key, secret_key, token, assumed_role = get_credentials()\n",
    "    update_aws_credentials_file(access_key, secret_key, token, assumed_role)\n",
    "    update_env_file(access_key, secret_key, token)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDED CODE TO GRNERATE THE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def suggest_and_plot(df):\n",
    "    # Analyze DataFrame structure\n",
    "    data_summary = df.describe().to_string() + \"\\n\" + str(df.info())\n",
    "\n",
    "    # Prompt for OpenAI\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following DataFrame and suggest the most suitable type of graph:\n",
    "\n",
    "    DataFrame Summary:\n",
    "    {data_summary}\n",
    "\n",
    "    Provide only the graph type (e.g., bar chart, scatter plot, histogram) and the columns to plot.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a data scientist and graph expert.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Task, Goal, or Current Prompt:\\n\" + prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    suggestion = response.choices[0].message.content.strip()\n",
    "    print(f\"Suggested Graph: {suggestion}\")\n",
    "\n",
    "    # Auto-generate the plot based on suggestion\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if \"bar chart\" in suggestion:\n",
    "        cat_col, num_col = suggestion.split(\":\")[1].strip().split(\",\")\n",
    "        sns.barplot(x=cat_col.strip(), y=num_col.strip(), data=df)\n",
    "    elif \"scatter plot\" in suggestion:\n",
    "        x_col, y_col = suggestion.split(\":\")[1].strip().split(\",\")\n",
    "        sns.scatterplot(x=x_col.strip(), y=y_col.strip(), data=df)\n",
    "    elif \"histogram\" in suggestion:\n",
    "        num_col = suggestion.split(\":\")[1].strip()\n",
    "        sns.histplot(df[num_col.strip()], kde=True)\n",
    "    elif \"heatmap\" in suggestion:\n",
    "        sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "    else:\n",
    "        print(\"Fallback: Pairplot\")\n",
    "        sns.pairplot(df)\n",
    "\n",
    "    plt.title(\"Auto-Generated Graph\")\n",
    "    plt.show()\n",
    "\n",
    "# Example DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"ElectricCarData_Clean.csv\")\n",
    "\n",
    "# Run the automated graph generator\n",
    "suggest_and_plot(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR CLAUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(self, pdf_context, csv_context, query, json_output_str):\n",
    "        prompt = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 2048,\n",
    "            \"system\": \"\"\"You are an expert AI assistant for Text-to-SQL conversion and data visualization.\n",
    "\n",
    "            **Task:**\n",
    "            - Analyze the provided PDF for context and the CSV data structure to understand the schema and answer the user's question:\n",
    "              1. If it requires data retrieval, generate a SQL query and summarize the answer using the PDF context.\n",
    "              2. If it doesn't require SQL querying, provide only an explanation and set the SQL query to null.\n",
    "              3. If the question involves time-based data or any data that would benefit from visualization (e.g., date ranges, timestamps, or categorical distributions), also generate a visualization using matplotlib or seaborn.\n",
    "            \"\"\",\n",
    "\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"Explanation:\\n{pdf_context}\\n\\nData Structure:\\n{csv_context}\\n\\nQuestion: {query}\\n\\n**Instructions:**\n",
    "\n",
    "            Format your response ONLY as a valid JSON object with these fields:\n",
    "            - Answer: Your explanation based on the PDF context\n",
    "            - SQL Query: The SQL query to retrieve the requested data, or null if no query is needed\n",
    "            - SQL Query Answer: The result of the SQL query in a simple format\n",
    "            - Visualization: When appropriate, include the following for matplotlib or seaborn:\n",
    "              - chart_type: The type of chart (e.g., 'bar', 'line', 'scatter')\n",
    "              - x: The x-axis data\n",
    "              - y: The y-axis data\n",
    "              - title: The chart title\n",
    "\n",
    "            For visualizations:\n",
    "            - Use appropriate chart types based on the data (bar charts for categorical data, line charts for time series, etc.)\n",
    "            - Keep the specification clean and minimal\n",
    "            - IMPORTANT: Do not add any text before or after the JSON object. Your entire response should be only the JSON object itself.\n",
    "\n",
    "            Example of exactly how your response should look:\n",
    "            {json_output_str}\"\"\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "\n",
    "        # Convert prompt to JSON string\n",
    "        input_text = json.dumps(prompt)\n",
    "\n",
    "        # Invoke Claude 3.5 Sonnet model\n",
    "        response = self.client.invoke_model(\n",
    "            modelId=os.getenv(\"MODEL_ID\"),\n",
    "            body=input_text\n",
    "        )\n",
    "\n",
    "        # Parse the response\n",
    "        response_body = json.loads(response['body'].read().decode(\"utf-8\"))\n",
    "        model_response = response_body['content'][0]['text']\n",
    "\n",
    "        try:\n",
    "            out = json.loads(model_response)\n",
    "            if 'Visualization' in out and out['Visualization']:\n",
    "                self.save_matplotlib_chart(out['Visualization'])\n",
    "            return out['SQL Query']\n",
    "        except Exception as e:\n",
    "            print(\"Error parsing model output:\", e)\n",
    "            return None\n",
    "\n",
    "def save_matplotlib_chart(chart_data):\n",
    "    chart_type = chart_data.get('chart_type', 'bar')\n",
    "    x = chart_data.get('x', [])\n",
    "    y = chart_data.get('y', [])\n",
    "    title = chart_data.get('title', 'Generated Chart')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if chart_type == 'bar':\n",
    "        sns.barplot(x=x, y=y)\n",
    "    elif chart_type == 'line':\n",
    "        sns.lineplot(x=x, y=y)\n",
    "    elif chart_type == 'scatter':\n",
    "        plt.scatter(x, y)\n",
    "    else:\n",
    "        print(\"Unsupported chart type\")\n",
    "        return\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"generated_chart.png\")\n",
    "    print(\"Chart saved to generated_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO READ THE INI FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Initialize parser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the .ini file\n",
    "config.read(\"config.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chainlit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "import httpx\n",
    "\n",
    "FASTAPI_BASE_URL = \"http://localhost:7047\"  # or your deployed URL\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"üëã Welcome to the Smart Runtime LITE Chainlit assistant!\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "    user_input = message.content.strip().lower()\n",
    "\n",
    "    if \"ping\" in user_input:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get(f\"{FASTAPI_BASE_URL}/ping\")\n",
    "            await cl.Message(content=f\"‚úÖ Ping Response:\\n{response.text}\").send()\n",
    "\n",
    "    elif \"team\" in user_input:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get(f\"{FASTAPI_BASE_URL}/team\")\n",
    "            await cl.Message(content=f\"üßë‚Äçüíª Team Info:\\n{response.text}\").send()\n",
    "\n",
    "    elif \"openapi\" in user_input:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get(f\"{FASTAPI_BASE_URL}/openapi.json\")\n",
    "            await cl.Message(content=f\"üìò OpenAPI JSON:\\n```json\\n{response.text}\\n```\").send()\n",
    "\n",
    "    else:\n",
    "        await cl.Message(content=\"ü§î I didn't understand that. Try asking about `ping`, `team`, or `openapi`.\").send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "# Static constants\n",
    "TEAM_ID = \"\"\n",
    "TEAM_VERSION = \"v1\"\n",
    "HERMES_BASE_URL = f\"\"\n",
    "AUTH_TOKEN = \"<your_token_here>\"  # Replace with your actual token\n",
    "\n",
    "@cl.on_message\n",
    "def handle_message(message: cl.Message):\n",
    "    try:\n",
    "        # Generate dynamic request ID and session ID\n",
    "        request_id = str(uuid.uuid4())\n",
    "        session_id = cl.user_session.get(\"session_id\") or str(uuid.uuid4())\n",
    "        cl.user_session.set(\"session_id\", session_id)\n",
    "\n",
    "        # You can replace with real username if available\n",
    "        session_user = cl.user_session.get(\"user\") or \"chainlit_user\"\n",
    "\n",
    "        # Build headers dynamically\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"request-id\": request_id,\n",
    "            \"session-id\": session_id,\n",
    "            \"session-user\": session_user\n",
    "        }\n",
    "\n",
    "        # Payload\n",
    "        payload = {\n",
    "            \"message\": message.content\n",
    "        }\n",
    "\n",
    "        # Call Hermes API\n",
    "        response = requests.post(HERMES_BASE_URL, json=payload, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            output = data[\"task_results\"][\"messages\"][-1][\"content\"]\n",
    "            cl.Message(content=f\"‚úÖ **Hermes Response:**\\n\\n{output}\").send()\n",
    "        else:\n",
    "            cl.Message(content=f\"‚ùå Hermes Error: {response.status_code}\\n{response.text}\").send()\n",
    "\n",
    "    except Exception as e:\n",
    "        cl.Message(content=f\"‚ö†Ô∏è Exception: {str(e)}\").send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "import requests\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    TEAM_ID = \"\"\n",
    "    TEAM_VERSION = \"\"\n",
    "    REQUEST_ID = \"\"\n",
    "    \n",
    "    url = f\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"request-id\": REQUEST_ID,\n",
    "        \"session-id\": \"your-session-id\",\n",
    "        \"session-user\": \"your-session-user\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            json={\"message\": message.content}\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            await cl.Message(content=f\"Hermes Response: {response.text}\").send()\n",
    "        else:\n",
    "            await cl.Message(content=f\"Hermes Error {response.status_code}: {response.text}\").send()\n",
    "\n",
    "    except Exception as e:\n",
    "        await cl.Message(content=f\"Error: {str(e)}\").send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAINLIT WITH AUTHENTICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "import requests\n",
    "\n",
    "AUTH_URL = \"\"\n",
    "CLIENT_ID = \"\"\n",
    "USERNAME = \"\"\n",
    "PASSWORD = \"\"  # Consider storing this securely!\n",
    "RESOURCE = \"\"\n",
    "\n",
    "def get_access_token():\n",
    "    payload = {\n",
    "        \"grant_type\": \"password\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"username\": USERNAME,\n",
    "        \"password\": PASSWORD,\n",
    "        \"resource\": RESOURCE\n",
    "    }\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    \n",
    "    response = requests.post(AUTH_URL, data=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"access_token\")\n",
    "    else:\n",
    "        raise Exception(f\"Token error {response.status_code}: {response.text}\")\n",
    "\n",
    "@cl.on_message\n",
    "async def main(message: cl.Message):\n",
    "    try:\n",
    "        token = get_access_token()\n",
    "\n",
    "        TEAM_ID = \"\"\n",
    "        TEAM_VERSION = \"\"\n",
    "        REQUEST_ID = \"\"\n",
    "        \n",
    "        url = f\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"request-id\": REQUEST_ID,\n",
    "            \"session-id\": \"your-session-id\",\n",
    "            \"session-user\": \"your-session-user\",\n",
    "            \"Authorization\": f\"Bearer {token}\"  # <-- Add this line\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            json={\"message\": message.content}\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            await cl.Message(content=f\"Hermes Response: {response.text}\").send()\n",
    "        else:\n",
    "            await cl.Message(content=f\"Hermes Error {response.status_code}: {response.text}\").send()\n",
    "\n",
    "    except Exception as e:\n",
    "        await cl.Message(content=f\"Error: {str(e)}\").send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.openapi.utils import get_openapi\n",
    "from starlette.middleware.cors import CORSMiddleware\n",
    "\n",
    "from app.router.invoke_router import run_invocation_router\n",
    "from app.router.ping_router import ping_router\n",
    "from app.router.team_router import team_smart_router\n",
    "from app.services.json_parser_svc import read_json_str, validate_and_register_team_config\n",
    "from app.services.log_svc import LogService\n",
    "from app.utils.agent_utils import current_date_time\n",
    "from app.utils import config\n",
    "from app.utils.client.ida_middleware import IDAMiddleware\n",
    "\n",
    "import chainlit as cl\n",
    "\n",
    "logger = LogService.get_logger(__name__)\n",
    "\n",
    "root_path = os.environ.get(\"APP_ROOT_PATH\", config.PROJECT_NAME)\n",
    "\n",
    "description = \"\"\"Smart Runtime API\"\"\"\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Smart CDAO Runtime LITE Application\",\n",
    "    version=\"0.0.1_\" + current_date_time(),\n",
    "    description=description,\n",
    "    contact={\n",
    "        \"name\": \"Smart Runtime LITE\",\n",
    "        \"url\": \"http://go/smartsdk\",\n",
    "        \"email\": \"DG_Agents_Registry_Dev@restricted.chase.com\"\n",
    "    },\n",
    "    swagger_ui_parameters={\n",
    "        \"filter\": True,\n",
    "        \"syntaxHighlight.theme\": \"nord\",\n",
    "        \"defaultModelsExpandDepth\": 3,\n",
    "        \"defaultModelExpandDepth\": 3,\n",
    "        \"displayRequestDuration\": True,\n",
    "        \"defaultModelRendering\": \"model\",\n",
    "        \"persistAuthorization\": True,\n",
    "        \"displayOperationId\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "# OpenAPI URL endpoints\n",
    "@app.get(f\"{root_path}/openapi.json\", include_in_schema=False)\n",
    "async def openapi() -> dict:\n",
    "    return get_openapi(title=app.title, version=app.version, routes=app.routes)\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Adjust as needed\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Include routers\n",
    "app.include_router(ping_router, prefix=root_path)\n",
    "app.include_router(run_invocation_router, prefix=root_path)\n",
    "app.include_router(team_smart_router, prefix=root_path)\n",
    "\n",
    "# Mount the FastAPI app to Chainlit\n",
    "cl.app.fastapi = app\n",
    "\n",
    "# Chainlit bot logic (if you want interaction, else remove this part)\n",
    "@cl.on_message\n",
    "async def main_logic(message: cl.Message):\n",
    "    await cl.Message(content=f\"You said: {message.content}\").send()\n",
    "\n",
    "# Run uvicorn server inside Chainlit process\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        logger.info(\"Starting uvicorn Server\")\n",
    "        validate_and_register_team_config(read_json_str())\n",
    "        uvicorn.run(app, host=\"0.0.0.0\", port=7047, timeout_keep_alive=1800)\n",
    "        logger.info(\"Started uvicorn Server\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPENSEARCH BLOGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://verticalserve.medium.com/advanced-rag-using-aws-opensearch-be7869042405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"data.json\")\n",
    "\n",
    "# Save to JSON file\n",
    "df.to_json('data.json', orient='records', lines=True)\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# Read JSON file\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('data.json', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip():  # Avoid empty lines\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(payload, f, indent=4)  # Proper double-quoted JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://docs.aws.amazon.com/opensearch-service/latest/developerguide/configuration-samples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import boto3\n",
    "\n",
    "# Create AWS authentication\n",
    "region = 'us-east-1'  # Replace with your region\n",
    "service = 'es'  # or 'aoss' for serverless\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(\n",
    "    credentials.access_key,\n",
    "    credentials.secret_key,\n",
    "    region,\n",
    "    service,\n",
    "    session_token=credentials.token\n",
    ")\n",
    "\n",
    "# Initialize OpenSearch client\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': 'your-domain-endpoint.region.es.amazonaws.com', 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GITHUB LINK FOR OPENSEARCH\n",
    "\n",
    "https://github.com/aws-samples/AI-search-with-amazon-opensearch-service/blob/main/OpenSearchApp/RAG/rag_DocumentSearcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API END POINT TO GET THE RESPONSE\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://your-api-url.com/endpoint\"  # Replace with your actual API URL\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",     # or as per the API docs\n",
    "    \"Authorization\": \"Bearer YOUR_API_KEY\"  # if needed\n",
    "}\n",
    "payload = {\n",
    "    \"key1\": \"value1\",\n",
    "    \"key2\": \"value2\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "# Print the response\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response JSON:\", response)  # or response.text if not JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STREAMLIT CODE \n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "\n",
    "st.set_page_config(page_title=\"üì° Single Key API Tester\", layout=\"centered\")\n",
    "st.title(\"üì° Test Your REST API\")\n",
    "\n",
    "# Input for single key\n",
    "user_input = st.text_input(\"Enter input value\")\n",
    "\n",
    "# Send button\n",
    "if st.button(\"Send Request\"):\n",
    "    url = \"http://localhost:8001/stream/graph/stream\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"key1\": user_input\n",
    "    }\n",
    "\n",
    "    with st.spinner(\"Sending request...\"):\n",
    "        try:\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "            st.success(f\"‚úÖ Status Code: {response.status_code}\")\n",
    "            st.code(response.json(), language=\"json\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"‚ùå Request failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "resp = ast.literal_eval(temp['summary'])\n",
    "\n",
    "\n",
    "st.markdown(f\"{resp['summary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Excel file\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "\n",
    "# Get unique values from a column (e.g., \"Name\")\n",
    "unique_names = df[\"Name\"].dropna().unique().tolist()\n",
    "\n",
    "# Create dropdown\n",
    "selected_name = st.selectbox(\"Choose a name\", unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m PROMT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mhey how are you !!\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43minp\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inp' is not defined"
     ]
    }
   ],
   "source": [
    "PROMT = f\"\"\"\n",
    "\n",
    "hey how are you !!\n",
    "\n",
    "\n",
    "{inp}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMT.foramt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hey how are you !!\n",
      "\n",
      "I'm good\n",
      "How about you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "hey how are you !!\n",
    "\n",
    "{first}\n",
    "{second}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = template.format(first=\"I'm good\", second=\"How about you?\")\n",
    "\n",
    "print(PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Get unique values from a column (e.g., \"Name\")\n",
    "unique_names = df[\"Name\"].dropna().unique().tolist()\n",
    "\n",
    "# Create dropdown\n",
    "selected_name = st.selectbox(\"Choose a name\", unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the datetime column is called \"timestamp\"\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors='coerce')\n",
    "\n",
    "# Get unique timestamps formatted as strings\n",
    "unique_timestamps = df[\"timestamp\"].dropna().dt.strftime(\"%Y-%m-%d %H:%M:%S\").unique().tolist()\n",
    "unique_timestamps = sorted(unique_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eventtimestamp'] = pd.to_datetime(df['eventtimestamp'], unit='s')\n",
    "\n",
    "ts = df['eventtimestamp'][0] \n",
    "\n",
    "ts.strftime(\"%Y-%m-%d %H:%M:%S\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert UNIX timestamp to datetime\n",
    "df['eventtimestamp'] = pd.to_datetime(df['eventtimestamp'], unit='s')\n",
    "\n",
    "# Get unique formatted timestamp strings\n",
    "unique_timestamps = df['eventtimestamp'].dropna().dt.strftime(\"%Y-%m-%d %H:%M:%S\").unique().tolist()\n",
    "\n",
    "# Sort the list\n",
    "unique_timestamps = sorted(unique_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.markdown(\"<span style='font-weight:bold; font-size:0.8rem;'>ADD YOUR TEXT OVER HER:</span>\", unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.markdown(\"<h1 style='font-size: 32px;'>Your Custom Title</h1>\", unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.image(\"your_image_path_or_url.png\", width=100)  # Adjust width as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.analyticsvidhya.com/program-dashboard/learner/progress/generative-ai-pinnacle-program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://huggingface.co/ByteDance/LatentSync-1.5/blob/main/latentsync_unet.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# === Claude 3.5 via Bedrock Config ===\n",
    "config_list_bedrock = [\n",
    "    {\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"meta.llama3-1-70b-instruct-v1:0\",\n",
    "        \"aws_region\": \"us-west-2\",\n",
    "        \"aws_access_key\": \"\",\n",
    "        \"aws_secret_key\": \"\",\n",
    "        \"temperature\": 0.1,\n",
    "        \"cache_seed\": None,  # turn off caching\n",
    "    }\n",
    "]\n",
    "\n",
    "# === Agent 1: Understand ===\n",
    "understand_agent = AssistantAgent(\n",
    "    name=\"CampaignUnderstandAgent\",\n",
    "    system_message=(\n",
    "        \"You are a campaign understanding agent. Interpret marketing goals and extract structured metadata.\\n\"\n",
    "        \"Return a plan with these keys: 'Target Audience', 'Behavior Filter', 'Preferred Channel', 'Email Tone', 'CTA'.\"\n",
    "    ),\n",
    "    llm_config={\"config_list\": config_list_bedrock},\n",
    ")\n",
    "\n",
    "# === Agent 2: Plan ===\n",
    "planner_agent = AssistantAgent(\n",
    "    name=\"CampaignPlannerAgent\",\n",
    "    system_message=(\n",
    "        \"You are a planning agent. Based on campaign metadata, write an SQL plan using available schema tables:\\n\"\n",
    "        \"DIGITAL_V, CUSTOMERCORE_V, MARKETING_V. Suggest joins and filters to select eligible users.\"\n",
    "    ),\n",
    "    llm_config={\"config_list\": config_list_bedrock},\n",
    ")\n",
    "\n",
    "# === Agent 3: Execute (mock executor for now) ===\n",
    "executor_agent = AssistantAgent(\n",
    "    name=\"SegmentExecutorAgent\",\n",
    "    system_message=(\n",
    "        \"You are an execution agent. Given an SQL plan, output mock user data as a list of profiles.\\n\"\n",
    "        \"Each profile includes: name, email, last_login_days, account_type.\"\n",
    "    ),\n",
    "    llm_config={\"config_list\": config_list_bedrock},\n",
    ")\n",
    "\n",
    "# === Agent 4: Generate Emails ===\n",
    "email_gen_agent = AssistantAgent(\n",
    "    name=\"EmailGenAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email generation agent. For each user profile, generate a personalized email.\\n\"\n",
    "        \"Format: Subject: <...>\\nBody: <...>. Use a friendly tone.\"\n",
    "    ),\n",
    "    llm_config={\"config_list\": config_list_bedrock},\n",
    ")\n",
    "\n",
    "# === Agent 5: Review ===\n",
    "review_agent = AssistantAgent(\n",
    "    name=\"EmailReviewerAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email QA reviewer. Review generated emails for tone, spam risk, personalization.\\n\"\n",
    "        \"Give a brief validation result.\"\n",
    "    ),\n",
    "    llm_config={\"config_list\": config_list_bedrock},\n",
    ")\n",
    "\n",
    "# === User Proxy ===\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxyAgent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"work_dir\": \"email_campaign_full\", \"use_docker\": False},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\")\n",
    ")\n",
    "\n",
    "# === Group Chat ===\n",
    "agents = [\n",
    "    user_proxy,\n",
    "    understand_agent,\n",
    "    planner_agent,\n",
    "    executor_agent,\n",
    "    email_gen_agent,\n",
    "    review_agent,\n",
    "]\n",
    "\n",
    "group = GroupChat(agents=agents, messages=[], max_round=8)\n",
    "manager = GroupChatManager(groupchat=group, llm_config={\"config_list\": config_list_bedrock})\n",
    "\n",
    "# === Start Flow ===\n",
    "def start_email_campaign():\n",
    "    campaign_objective = (\n",
    "        \"Launch a campaign to re-engage users who haven't logged in to digital banking in over 45 days.\\n\"\n",
    "        \"Use email as the primary channel. Tone: friendly and helpful.\\n\"\n",
    "        \"Offer: highlight new features + easy reactivation.\\n\"\n",
    "        \"TERMINATE\"\n",
    "    )\n",
    "    user_proxy.initiate_chat(manager, message=campaign_objective)\n",
    "\n",
    "    print(\"\\n==== Agent Messages ====\")\n",
    "    all_messages = []\n",
    "    for msg in group.messages:\n",
    "        sender = msg.get(\"name\", \"Unknown\")\n",
    "        content = msg.get(\"content\", \"\")\n",
    "        print(f\"\\nFrom: {sender}\\n{'-'*20}\\n{content}\\n\")\n",
    "        all_messages.append({\"from\": sender, \"content\": content})\n",
    "\n",
    "    # Save to JSON file\n",
    "    with open(\"agent_outputs.json\", \"w\") as f:\n",
    "        json.dump(all_messages, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_email_campaign()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "# === Step 1: Setup BedrockInfo ===\n",
    "bedrock_info = BedrockInfo(\n",
    "    aws_access_key=\"YOUR_AWS_ACCESS_KEY\",\n",
    "    aws_secret_key=\"YOUR_AWS_SECRET_KEY\",\n",
    "    aws_session_token=\"YOUR_SESSION_TOKEN\",  # optional\n",
    "    aws_region=\"us-west-2\"\n",
    ")\n",
    "\n",
    "# === Step 2: Setup Model Client ===\n",
    "llm_client = AnthropicBedrockChatCompletionClient(\n",
    "    model=\"\",  # or Claude model ARN if needed\n",
    "    model_info=ModelInfo(\n",
    "        vision=False,\n",
    "        function_calling=True,\n",
    "        json_output=False,\n",
    "        family=\"llama3\",\n",
    "        structured_output=True\n",
    "    ),\n",
    "    bedrock_info=bedrock_info\n",
    ")\n",
    "\n",
    "# === Step 3: Shared LLM Config ===\n",
    "llm_config = {\n",
    "    \"client\": llm_client\n",
    "}\n",
    "\n",
    "# === Agent 1: Understand ===\n",
    "understand_agent = AssistantAgent(\n",
    "    name=\"CampaignUnderstandAgent\",\n",
    "    system_message=(\n",
    "        \"You are a campaign understanding agent. Interpret marketing goals and extract structured metadata.\\n\"\n",
    "        \"Return a plan with these keys: 'Target Audience', 'Behavior Filter', 'Preferred Channel', 'Email Tone', 'CTA'.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# === Agent 2: Plan ===\n",
    "planner_agent = AssistantAgent(\n",
    "    name=\"CampaignPlannerAgent\",\n",
    "    system_message=(\n",
    "        \"You are a planning agent. Based on campaign metadata, write an SQL plan using available schema tables:\\n\"\n",
    "        \"DIGITAL_V, CUSTOMERCORE_V, MARKETING_V. Suggest joins and filters to select eligible users.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# === Agent 3: Execute (mock executor) ===\n",
    "executor_agent = AssistantAgent(\n",
    "    name=\"SegmentExecutorAgent\",\n",
    "    system_message=(\n",
    "        \"You are an execution agent. Given an SQL plan, output mock user data as a list of profiles.\\n\"\n",
    "        \"Each profile includes: name, email, last_login_days, account_type.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# === Agent 4: Generate Emails ===\n",
    "email_gen_agent = AssistantAgent(\n",
    "    name=\"EmailGenAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email generation agent. For each user profile, generate a personalized email.\\n\"\n",
    "        \"Format: Subject: <...>\\nBody: <...>. Use a friendly tone.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# === Agent 5: Review ===\n",
    "review_agent = AssistantAgent(\n",
    "    name=\"EmailReviewerAgent\",\n",
    "    system_message=(\n",
    "        \"You are an email QA reviewer. Review generated emails for tone, spam risk, personalization.\\n\"\n",
    "        \"Give a brief validation result.\"\n",
    "    ),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# === User Proxy ===\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"UserProxyAgent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"work_dir\": \"email_campaign_full\", \"use_docker\": False},\n",
    "    max_consecutive_auto_reply=1,\n",
    "    is_termination_msg=lambda x: \"TERMINATE\" in x.get(\"content\", \"\")\n",
    ")\n",
    "\n",
    "# === Group Chat ===\n",
    "agents = [\n",
    "    user_proxy,\n",
    "    understand_agent,\n",
    "    planner_agent,\n",
    "    executor_agent,\n",
    "    email_gen_agent,\n",
    "    review_agent,\n",
    "]\n",
    "\n",
    "group = GroupChat(agents=agents, messages=[], max_round=8)\n",
    "manager = GroupChatManager(groupchat=group, llm_config=llm_config)\n",
    "\n",
    "# === Main Execution ===\n",
    "def start_email_campaign():\n",
    "    campaign_objective = (\n",
    "        \"Launch a campaign to re-engage users who haven't logged in to digital banking in over 45 days.\\n\"\n",
    "        \"Use email as the primary channel. Tone: friendly and helpful.\\n\"\n",
    "        \"Offer: highlight new features + easy reactivation.\\n\"\n",
    "        \"TERMINATE\"\n",
    "    )\n",
    "    user_proxy.initiate_chat(manager, message=campaign_objective)\n",
    "\n",
    "    print(\"\\n==== Agent Messages ====\")\n",
    "    all_messages = []\n",
    "    for msg in group.messages:\n",
    "        sender = msg.get(\"name\", \"Unknown\")\n",
    "        content = msg.get(\"content\", \"\")\n",
    "        print(f\"\\nFrom: {sender}\\n{'-'*20}\\n{content}\\n\")\n",
    "        all_messages.append({\"from\": sender, \"content\": content})\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(\"agent_outputs.json\", \"w\") as f:\n",
    "        json.dump(all_messages, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_email_campaign()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent\n",
    "from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient, BedrockInfo\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "# === Step 1: Setup Bedrock Credentials ===\n",
    "bedrock_info = BedrockInfo(\n",
    "    aws_access_key=\"YOUR_ACCESS_KEY\",         # üü° Replace this\n",
    "    aws_secret_key=\"YOUR_SECRET_KEY\",         # üü° Replace this\n",
    "    aws_region=\"us-west-2\"\n",
    ")\n",
    "\n",
    "# === Step 2: Initialize Claude Client via Bedrock ===\n",
    "llm_client = AnthropicBedrockChatCompletionClient(\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # ‚úÖ Claude 3.5 Sonnet ARN (or another valid Bedrock model)\n",
    "    model_info=ModelInfo(\n",
    "        vision=False,\n",
    "        function_calling=True,\n",
    "        json_output=False,\n",
    "        family=\"claude-3\",\n",
    "        structured_output=True\n",
    "    ),\n",
    "    bedrock_info=bedrock_info\n",
    ")\n",
    "\n",
    "# === Step 3: Agent 1 - Campaign Understand Agent ===\n",
    "understand_agent = AssistantAgent(\n",
    "    name=\"CampaignUnderstandAgent\",\n",
    "    system_message=(\n",
    "        \"You are a campaign understanding agent. Interpret marketing goals and extract structured metadata.\\n\"\n",
    "        \"Return a plan with these keys: 'Target Audience', 'Behavior Filter', 'Preferred Channel', 'Email Tone', 'CTA'.\"\n",
    "    ),\n",
    "    llm_config={\"client\": llm_client}  # ‚úÖ Use Claude client\n",
    ")\n",
    "\n",
    "# === Step 4: Test Run ===\n",
    "response = understand_agent.generate_reply(messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"We want to re-engage digital banking users inactive for over 45 days. Use friendly tone and email channel.\"\n",
    "    }\n",
    "])\n",
    "\n",
    "# === Output Result ===\n",
    "print(\"üß† Agent 1 Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen import AssistantAgent\n",
    "from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "# === Step 1: Setup Bedrock Credentials ===\n",
    "# Option A: Use AWS credentials from environment/profile (recommended)\n",
    "# Make sure you have AWS CLI configured or set these environment variables:\n",
    "# export AWS_ACCESS_KEY_ID=\"your_access_key\"\n",
    "# export AWS_SECRET_ACCESS_KEY=\"your_secret_key\" \n",
    "# export AWS_DEFAULT_REGION=\"us-west-2\"\n",
    "\n",
    "# Option B: Explicit credentials (not recommended for production)\n",
    "bedrock_config = {\n",
    "    \"aws_access_key_id\": \"YOUR_ACCESS_KEY\",      # Replace with actual key\n",
    "    \"aws_secret_access_key\": \"YOUR_SECRET_KEY\",  # Replace with actual secret\n",
    "    \"region_name\": \"us-west-2\"                   # Ensure Claude is available in this region\n",
    "}\n",
    "\n",
    "# === Step 2: Initialize Claude Client via Bedrock ===\n",
    "llm_client = AnthropicBedrockChatCompletionClient(\n",
    "    # ‚úÖ Use correct Claude 3.5 Sonnet model ID for Bedrock\n",
    "    model=\"model arn \",  # Updated model ID\n",
    "    \n",
    "    # ‚úÖ Correct model info configuration\n",
    "    model_info=ModelInfo(\n",
    "        vision=True,           # Claude 3.5 Sonnet supports vision\n",
    "        function_calling=True, # Supports function calling\n",
    "        json_output=True,      # Supports JSON output\n",
    "        family=\"claude-3.5\"    # Correct family name\n",
    "    ),\n",
    "    \n",
    "    # ‚úÖ Pass credentials properly\n",
    "    **bedrock_config  # Unpack the credentials\n",
    ")\n",
    "\n",
    "# === Step 3: Agent 1 - Campaign Understand Agent ===\n",
    "understand_agent = AssistantAgent(\n",
    "    name=\"CampaignUnderstandAgent\",\n",
    "    system_message=(\n",
    "        \"You are a campaign understanding agent. Interpret marketing goals and extract structured metadata.\\n\"\n",
    "        \"Return a JSON plan with these keys: 'target_audience', 'behavior_filter', 'preferred_channel', 'email_tone', 'cta'.\\n\"\n",
    "        \"Be specific and actionable in your recommendations.\"\n",
    "    ),\n",
    "    llm_config={\n",
    "        \"config_list\": [{\n",
    "            \"model\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "            \"api_type\": \"bedrock\",\n",
    "            \"client\": llm_client\n",
    "        }],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    ")\n",
    "\n",
    "# === Step 4: Async Test Run (Required for newer AutoGen versions) ===\n",
    "async def test_agent():\n",
    "    try:\n",
    "        response = await understand_agent.a_generate_reply(messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"We want to re-engage digital banking users inactive for over 45 days. Use friendly tone and email channel.\"\n",
    "            }\n",
    "        ])\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# === Step 5: Alternative Synchronous Approach ===\n",
    "def test_agent_sync():\n",
    "    try:\n",
    "        # For synchronous call, ensure proper message format\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"We want to re-engage digital banking users inactive for over 45 days. Use friendly tone and email channel.\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        response = understand_agent.generate_reply(\n",
    "            messages=messages,\n",
    "            sender=None  # Add sender parameter\n",
    "        )\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Sync Error: {e}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        return None\n",
    "\n",
    "# === Step 6: Run the test ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Testing AutoGen with Claude via Bedrock...\")\n",
    "    \n",
    "    # Try async first\n",
    "    try:\n",
    "        result = asyncio.run(test_agent())\n",
    "        if result:\n",
    "            print(\"üß† Async Agent Response:\\n\", result)\n",
    "    except Exception as e:\n",
    "        print(f\"Async failed: {e}\")\n",
    "        \n",
    "        # Fallback to sync\n",
    "        print(\"\\nüîÑ Trying synchronous approach...\")\n",
    "        result = test_agent_sync()\n",
    "        if result:\n",
    "            print(\"üß† Sync Agent Response:\\n\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Testing AutoGen with Claude via Bedrock...\")\n",
    "    \n",
    "    try:\n",
    "        result = asyncio.run(test_agent())\n",
    "        if result:\n",
    "            print(\"üß† Async Agent Response:\\n\", result)\n",
    "    except Exception as e:\n",
    "        print(f\"Async failed: {e}\")\n",
    "        \n",
    "        # Fallback to sync\n",
    "        print(\"\\nüîÑ Trying synchronous approach...\")\n",
    "        result = test_agent_sync()\n",
    "        if result:\n",
    "            print(\"üß† Sync Agent Response:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sarevsh  hsjas aksjia\n",
      "0   ajsja  asjha  alsnj\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample row (simulated using a dictionary or named tuple)\n",
    "row = dict(sarevsh='ajsja', hsjas='asjha', aksjia='alsnj')\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame([row])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
