{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U  boto3 huggingface_hub==0.24.5 mteb==1.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/aws-samples/amazon-bedrock-samples/blob/main/embeddings/Titan-V2-Embeddings.ipynb\n",
    "\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "def get_bedrock_client(assumed_role: Optional[str] = None, region: Optional[str] = 'us-east-1',runtime: Optional[bool] = True,external_id=None, ep_url=None):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides \n",
    "    \"\"\"\n",
    "    target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}:external_id={external_id}: \")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        if external_id:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "                ExternalId=external_id\n",
    "            )\n",
    "        else:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "            )\n",
    "        print(f\"Using role: {assumed_role} ... sts::successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    if ep_url:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config,endpoint_url = ep_url, **client_kwargs )\n",
    "    else:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config, **client_kwargs )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "class TitanEmbeddings(object):\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    def __init__(self, model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=None, region_name='us-east-1'):\n",
    "        \n",
    "        if boto3_client:\n",
    "            self.bedrock_boto3 = boto3_client\n",
    "        else:\n",
    "            # self.bedrock_boto3 = boto3.client(service_name='bedrock-runtime')\n",
    "            self.bedrock_boto3 = boto3.client(\n",
    "                service_name='bedrock-runtime', \n",
    "                region_name=region_name, \n",
    "            )\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def __call__(self, text, dimensions, normalize=True):\n",
    "        \"\"\"\n",
    "        Returns Titan Embeddings\n",
    "\n",
    "        Args:\n",
    "            text (str): text to embed\n",
    "            dimensions (int): Number of output dimensions.\n",
    "            normalize (bool): Whether to return the normalized embedding or not.\n",
    "\n",
    "        Return:\n",
    "            List[float]: Embedding\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        body = json.dumps({\n",
    "            \"inputText\": text,\n",
    "            \"dimensions\": dimensions,\n",
    "            \"normalize\": normalize\n",
    "        })\n",
    "\n",
    "        response = self.bedrock_boto3.invoke_model(\n",
    "            body=body, modelId=self.model_id, accept=self.accept, contentType=self.content_type\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "\n",
    "        return response_body['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "boto3_bedrock_runtime = get_bedrock_client() #boto3.client('bedrock')\n",
    "\n",
    "bedrock_embeddings = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=boto3_bedrock_runtime)\n",
    "bedrock_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = \"Amazon Bedrock supports foundation models from industry-leading providers such as \\\n",
    "AI21 Labs, Anthropic, Stability AI, and Amazon. Choose the model that is best suited to achieving \\\n",
    "your unique goals.\"\n",
    "\n",
    "\n",
    "modelId = \"amazon.titan-embed-text-v2:0\"  # \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "\n",
    "\n",
    "sample_model_input={\n",
    "    \"inputText\": prompt_data,\n",
    "    \"dimensions\": 256,\n",
    "    \"normalize\": True\n",
    "}\n",
    "\n",
    "body = json.dumps(sample_model_input)\n",
    "\n",
    "response = boto3_bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "embedding = response_body.get(\"embedding\")\n",
    "print(f\"The embedding vector has {len(embedding)} values\\n{embedding[0:3]+['...']+embedding[-3:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding= bedrock_embeddings(text=prompt_data, dimensions=256, normalize=True)\n",
    "print(f\"The embedding vector has {len(embedding)} values\\n{embedding[0:3]+['...']+embedding[-3:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/aws-samples/amazon-bedrock-samples/blob/main/genai-use-cases/aws-glue-metadata-generation/how_to_generate_metadata_for_glue_data_catalog_w_bedrock.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import boto3 \n",
    "from botocore.config import Config\n",
    "from typing import Optional\n",
    "import langchain\n",
    "import logging\n",
    "from datetime import date, datetime\n",
    "import pprint \n",
    "\n",
    "\n",
    "def get_bedrock_client(\n",
    "    assumed_role: Optional[str] = None,\n",
    "    region: Optional[str] = None,\n",
    "    runtime: Optional[bool] = True,\n",
    "):\n",
    "    #  create a boto3 session with the specified region and, optionally, an AWS profile name from the `AWS_PROFILE` environment variable.\n",
    "    if region is None: \n",
    "        target_region = os.environ.get(\"AWS_REGION\", os.environ.get(\"AWS_DEFAULT_REGION\"))\n",
    "    else:\n",
    "        target_region = region\n",
    "\n",
    "    print(f\"Create new client\\n  Using region: {target_region}\")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    # if an `assumed_role` is provided assume that role using STS and retrieve the temporary credential for the client.\n",
    "    if assumed_role: \n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        print(assumed_role)\n",
    "        response = sts.assume_role(\n",
    "            RoleArn=str(assumed_role),\n",
    "            RoleSessionName=\"langchain-llm-1\"\n",
    "        )\n",
    "        print(\" ... successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    # create the boto3 client for the `bedrock-runtime` or `bedrock` service, based on the `runtime` flag, with the specified region, credentials (if assumed role is used), and a retry configuration.\n",
    "    bedrock_client = session.client(\n",
    "        service_name=service_name,\n",
    "        config=retry_config,\n",
    "        **client_kwargs\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_client._endpoint)\n",
    "    return bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "embeddings_model_id= \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"  # E.g. \"us-east-1\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "GLUE_CRAWLER_ARN = '<YOUR_AWS_GLUE_CRAWLER_IAM_ROLE>'\n",
    "\n",
    "bedrock_client= get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "\n",
    "test_client = boto3.client(\"default\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "response = litellm.embedding(\n",
    "    model=\"bedrock/amazon.titan-embed-text-v1\",\n",
    "    model_id=\"provisioned-model-arn\",\n",
    "    input=[\"hi\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPRAOCH 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the AWS Bedrock runtime client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\"  # Ensure this matches your ARN region\n",
    ")\n",
    "\n",
    "# Define the model ARN\n",
    "model_arn = \"arn:aws:bedrock:us-east-1:942286715197:application-inference-profile/4eix5vfvs8bmm\"\n",
    "model_arn = \"amazon.titan-embed-text-v2:0\"\n",
    "# Define the input text\n",
    "input_text = \"This is a test sentence for embedding generation.\"\n",
    "\n",
    "# Construct the payload (modify as needed based on model requirements)\n",
    "payload = {\n",
    "    \"inputText\": input_text\n",
    "}\n",
    "\n",
    "# Invoke the embedding model\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=model_arn, \n",
    "    contentType=\"application/json\",\n",
    "    body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# Parse and print the response\n",
    "response_body = json.loads(response[\"body\"].read())\n",
    "print(response_body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def get_embeddings_with_profile(text, profile_arn, region=\"us-east-1\"):\n",
    "    \"\"\"\n",
    "    Get embeddings using a Bedrock application inference profile ARN.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to embed\n",
    "        profile_arn (str): The ARN of the Bedrock application inference profile\n",
    "        region (str): AWS region where Bedrock is available\n",
    "        \n",
    "    Returns:\n",
    "        list: The embedding vector\n",
    "    \"\"\"\n",
    "    # Create a boto3 session for the specified region\n",
    "    session = boto3.Session(region_name=region)\n",
    "    \n",
    "    # Create a Bedrock Runtime client\n",
    "    bedrock_runtime = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=region\n",
    "    )\n",
    "    \n",
    "    # Prepare the request body\n",
    "    request_body = {\n",
    "        \"inputText\": text\n",
    "    }\n",
    "    \n",
    "    # Convert the request body to bytes\n",
    "    body = json.dumps(request_body).encode('utf-8')\n",
    "    \n",
    "    # Invoke the model using the application inference profile\n",
    "    response = bedrock_runtime.invoke_model_with_application_inference_profile(\n",
    "        applicationInferenceProfileArn=profile_arn,\n",
    "        body=body\n",
    "    )\n",
    "    \n",
    "    # Parse the response\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    embedding = response_body.get('embedding')\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Your specific application inference profile ARN\n",
    "    profile_arn = \"arn:aws:bedrock:us-east-1:942286715197:application-inference-profile/4eix5vfvs8bmm\"\n",
    "    region = \"us-east-1\"\n",
    "    \n",
    "    text = \"This is a sample text to embed.\"\n",
    "    embedding = get_embeddings_with_profile(text, profile_arn, region)\n",
    "    \n",
    "    # Print embedding dimensions\n",
    "    print(f\"Embedding dimension: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPRAOCH 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings import BedrockEmbedding\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "class BedrockProfileEmbedding:\n",
    "    def __init__(self, profile_arn, region=\"us-east-1\"):\n",
    "        # Initialize boto3 client\n",
    "        session = boto3.Session(region_name=region)\n",
    "        self.client = session.client('bedrock-runtime')\n",
    "        self.profile_arn = profile_arn\n",
    "        self.dimension = None  # Will be set after first embedding\n",
    "        \n",
    "    def _get_embedding(self, text):\n",
    "        request_body = {\"inputText\": text}\n",
    "        body = json.dumps(request_body).encode('utf-8')\n",
    "        \n",
    "        response = self.client.invoke_model_with_application_inference_profile(\n",
    "            applicationInferenceProfileArn=self.profile_arn,\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        embedding = response_body.get('embedding')\n",
    "        \n",
    "        # Set dimension if not already set\n",
    "        if self.dimension is None and embedding:\n",
    "            self.dimension = len(embedding)\n",
    "            \n",
    "        return embedding\n",
    "    \n",
    "    def get_text_embedding(self, text):\n",
    "        return self._get_embedding(text)\n",
    "        \n",
    "    def get_query_embedding(self, query):\n",
    "        return self._get_embedding(query)\n",
    "    \n",
    "    # Required methods for LlamaIndex compatibility\n",
    "    def embed_documents(self, documents):\n",
    "        return [self.get_text_embedding(doc.text) for doc in documents]\n",
    "    \n",
    "    def embed_query(self, query):\n",
    "        return self.get_query_embedding(query)\n",
    "\n",
    "# Example usage with LlamaIndex\n",
    "def index_documents_with_bedrock():\n",
    "    # Your application inference profile ARN\n",
    "    profile_arn = \"arn:aws:bedrock:us-east-1:942286715197:application-inference-profile/4eix5vfvs8bmm\"\n",
    "    \n",
    "    # Create custom embedding model\n",
    "    embed_model = BedrockProfileEmbedding(profile_arn)\n",
    "    \n",
    "    # Create sample documents\n",
    "    documents = [\n",
    "        Document(text=\"This is a document about artificial intelligence.\"),\n",
    "        Document(text=\"Embeddings are vector representations of text.\"),\n",
    "        Document(text=\"LlamaIndex helps with RAG applications.\")\n",
    "    ]\n",
    "    \n",
    "    # Create vector index using our Bedrock embeddings\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    \n",
    "    # Create a query engine\n",
    "    query_engine = index.as_query_engine()\n",
    "    \n",
    "    # Execute a query\n",
    "    response = query_engine.query(\"What are embeddings?\")\n",
    "    \n",
    "    print(\"Query response:\")\n",
    "    print(response)\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Run the example\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting document indexing with Bedrock application inference profile...\")\n",
    "    index = index_documents_with_bedrock()\n",
    "    print(\"Indexing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\"\"\"\n",
    "Shows how to generate an embedding with the Amazon Titan Embeddings G1 - Text model (on demand).\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def generate_embedding(model_id, body):\n",
    "    \"\"\"\n",
    "    Generate an embedding with the vector representation of a text input using Amazon Titan Embeddings G1 - Text on demand.\n",
    "    Args:\n",
    "        model_id (str): The model ID to use.\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        response (JSON): The embedding created by the model and the number of input tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Generating an embedding with Amazon Titan Embeddings G1 - Text model %s\", model_id)\n",
    "\n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=model_id, accept=accept, contentType=content_type\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entrypoint for Amazon Titan Embeddings G1 - Text example.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    model_id = \"amazon.titan-embed-text-v1\"\n",
    "    input_text = \"What are the different services that you offer?\"\n",
    "\n",
    "\n",
    "    # Create request body.\n",
    "    body = json.dumps({\n",
    "        \"inputText\": input_text,\n",
    "    })\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = generate_embedding(model_id, body)\n",
    "\n",
    "        print(f\"Generated an embedding: {response['embedding']}\")\n",
    "        print(f\"Input Token count:  {response['inputTextTokenCount']}\")\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response[\"Error\"][\"Message\"]\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        print(\"A client error occured: \" +\n",
    "              format(message))\n",
    "\n",
    "    else:\n",
    "        print(f\"Finished generating an embedding with Amazon Titan Embeddings G1 - Text model {model_id}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', \n",
    "                              region_name='us-east-1')\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
    "                                       client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "\n",
    "vectorstore_faiss = FAISS.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings,\n",
    ")\n",
    "\n",
    "\n",
    "# faiss.write_index(vectorstore_faiss.index, \"../../data/index/prompt_embeddings.index\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
